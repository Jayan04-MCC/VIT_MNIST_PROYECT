# Vision Transformer en C++ - Plan de Desarrollo de 5 DÃ­as

Eres un desarrollador experto en C++ encargado de implementar un Vision Transformer (ViT) desde cero para clasificaciÃ³n de MNIST. Sigue este plan estructurado de 5 dÃ­as para construir una implementaciÃ³n completa y funcional.

## ğŸ¯ Objetivos Generales del Proyecto
- Crear un Vision Transformer completamente funcional en C++
- Implementar todos los componentes desde cero (sin librerÃ­as de ML externas)
- Lograr resultados comparables a la implementaciÃ³n de referencia en PyTorch
- Enfocarse en claridad del cÃ³digo y correcciÃ³n antes que optimizaciÃ³n

## ğŸ“‹ Estructura del Proyecto
```
vision_transformer_cpp/
â”œâ”€â”€ include/
â”‚   â”œâ”€â”€ matrix/
â”‚   â”‚   â”œâ”€â”€ matrix.h
â”‚   â”‚   â”œâ”€â”€ matrix_ops.h
â”‚   â”‚   â””â”€â”€ activation_functions.h
â”‚   â”œâ”€â”€ transformer/
â”‚   â”‚   â”œâ”€â”€ embedding.h
â”‚   â”‚   â”œâ”€â”€ layer_norm.h
â”‚   â”‚   â”œâ”€â”€ attention.h
â”‚   â”‚   â”œâ”€â”€ mlp.h
â”‚   â”‚   â””â”€â”€ transformer.h
â”‚   â””â”€â”€ utils/
â”‚       â”œâ”€â”€ file_io.h
â”‚       â””â”€â”€ image_processing.h
â”œâ”€â”€ src/
â”œâ”€â”€ tests/
â””â”€â”€ data/
    â””â”€â”€ weights_csv_organized/
```

---

## ğŸ“… DÃA 1: Fundamentos - LibrerÃ­a de Matrices (6-8 horas)
**Prioridad: Construir una base matemÃ¡tica sÃ³lida**

### SesiÃ³n Matutina (3-4 horas): Clase Matrix Principal
Crear `include/matrix/matrix.h` y `src/matrix/matrix.cpp`:

**Requisitos Esenciales:**
- Matriz 2D dinÃ¡mica con asignaciÃ³n en heap
- Constructor: `Matrix(int rows, int cols)`
- Acceso a elementos: `operator()(int i, int j)` y `at(int i, int j)`
- Manejo de memoria: destructor apropiado y constructor de copia
- MÃ©todos de inicializaciÃ³n: `zeros()`, `ones()`, `random()`
- Getters de dimensiones: `rows()`, `cols()`, `size()`
- MÃ©todo de debug: `print()` con formato

**Notas CrÃ­ticas de ImplementaciÃ³n:**
- Usar almacenamiento row-major (`data[i*cols + j]`)
- Implementar verificaciÃ³n de lÃ­mites con assertions
- Manejar fallos de asignaciÃ³n de memoria elegantemente

### SesiÃ³n Vespertina (3-4 horas): Operaciones de Matrices
Crear `include/matrix/matrix_ops.h` y `src/matrix/matrix_ops.cpp`:

**Operaciones Principales:**
- MultiplicaciÃ³n de matrices: `matmul(const Matrix& A, const Matrix& B)`
- Operaciones elemento a elemento: `add()`, `subtract()`, `multiply()`
- Operaciones de forma: `transpose()`, `reshape()`
- Broadcasting: soporte bÃ¡sico para operaciones escalares

**Consideraciones de Rendimiento:**
- Optimizar multiplicaciÃ³n de matrices con loop tiling
- Agregar verificaciones de compatibilidad de dimensiones
- Usar referencias `const` para parÃ¡metros de entrada

### SesiÃ³n Nocturna (1 hora): Sistema de E/S de Archivos
Crear `include/utils/file_io.h` y `src/utils/file_io.cpp`:

**Funciones de Carga de Archivos:**
- `load_matrix_from_csv(const string& filename)`
- `load_vector_from_csv(const string& filename)`
- Manejo de errores para archivos mal formados
- Soporte para diferentes delimitadores

### ğŸ¯ Criterios de Ã‰xito del DÃ­a 1:
- [ ] La clase Matrix pasa todas las pruebas de operaciones bÃ¡sicas
- [ ] La multiplicaciÃ³n de matrices funciona correctamente para varios tamaÃ±os
- [ ] La carga de CSV funciona con archivos de datos de muestra
- [ ] Sin fugas de memoria (verificar con valgrind si estÃ¡ disponible)

---

## ğŸ“… DÃA 2: Componentes de Red Neuronal (6-8 horas)
**Prioridad: Implementar funciones de activaciÃ³n y normalizaciÃ³n**

### SesiÃ³n Matutina (2-3 horas): Funciones de ActivaciÃ³n
Crear `include/matrix/activation_functions.h` y `src/matrix/activation_functions.cpp`:

**Funciones Requeridas:**
- `softmax(const Matrix& input)` - con estabilidad numÃ©rica
- `gelu(const Matrix& input)` - Gaussian Error Linear Unit
- `relu(const Matrix& input)` - para propÃ³sitos de debugging

**ImplementaciÃ³n de GELU:**
```cpp
// GELU(x) = x * Î¦(x) donde Î¦ es CDF de la normal estÃ¡ndar
// AproximaciÃ³n: GELU(x) â‰ˆ 0.5 * x * (1 + tanh(âˆš(2/Ï€) * (x + 0.044715 * xÂ³)))
```

**Estabilidad de Softmax:**
- Restar valor mÃ¡ximo antes del exponencial
- Manejar casos extremos (todos ceros, valores muy grandes)

### SesiÃ³n Vespertina (3-4 horas): NormalizaciÃ³n de Capas
Crear `include/transformer/layer_norm.h` y `src/transformer/layer_norm.cpp`:

**Funcionalidad Principal:**
- MÃ©todo `forward(const Matrix& input)`
- ParÃ¡metros: vectores `gamma` (escala) y `beta` (desplazamiento)
- Calcular media y varianza a travÃ©s de la dimensiÃ³n de caracterÃ­sticas
- Normalizar: `(x - media) / sqrt(varianza + epsilon)`
- Aplicar parÃ¡metros aprendidos: `gamma * normalizado + beta`

**Detalles de ImplementaciÃ³n:**
- Epsilon por defecto: 1e-5 para estabilidad numÃ©rica
- `load_weights(const string& base_path)` - carga desde tu estructura CSV:
  - Para capas transformer: `base_path + "/transformer_layers/blocks_X_norm1_weight.csv"`
  - Para norm final: `base_path + "/layer_norm/norm_weight.csv"`
- Soporte para diferentes dimensiones de entrada

**Ejemplo de Carga de Pesos:**
```cpp
void LayerNorm::load_weights(const string& base_path, int layer_idx, const string& norm_type) {
    string weight_path = base_path + "/transformer_layers/blocks_" + 
                        std::to_string(layer_idx) + "_" + norm_type + "_weight.csv";
    string bias_path = base_path + "/transformer_layers/blocks_" + 
                      std::to_string(layer_idx) + "_" + norm_type + "_bias.csv";
    gamma = load_vector_from_csv(weight_path);
    beta = load_vector_from_csv(bias_path);
}
```

### SesiÃ³n Nocturna (2 horas): Capa de Embedding
Crear `include/transformer/embedding.h` y `src/transformer/embedding.cpp`:

**Patch Embedding:**
- Convertir parches de imagen a vectores de caracterÃ­sticas
- ProyecciÃ³n lineal: `parches * matriz_peso + bias`
- Agregar token de clase aprendible al inicio
- Agregar embeddings posicionales

**MÃ©todos Clave:**
- `forward(const Matrix& image_patches)`
- `load_weights(const string& base_path)` - carga desde tu estructura CSV:
  - `base_path + "/patch_embedding/patch_proj_weight.csv"`
  - `base_path + "/patch_embedding/patch_proj_bias.csv"`
  - `base_path + "/position_embedding/pos_embed.csv"`
  - `base_path + "/class_token/cls_token.csv"`
- Manejar diferentes tamaÃ±os de parches y dimensiones de imagen

**Ejemplo de Carga de Pesos:**
```cpp
void PatchEmbedding::load_weights(const string& base_path) {
    proj_weight = load_matrix_from_csv(base_path + "/patch_embedding/patch_proj_weight.csv");
    proj_bias = load_vector_from_csv(base_path + "/patch_embedding/patch_proj_bias.csv");
    pos_embed = load_matrix_from_csv(base_path + "/position_embedding/pos_embed.csv");
    cls_token = load_matrix_from_csv(base_path + "/class_token/cls_token.csv");
}
```

### ğŸ¯ Criterios de Ã‰xito del DÃ­a 2:
- [ ] Todas las funciones de activaciÃ³n producen salidas esperadas
- [ ] La normalizaciÃ³n de capas coincide con la implementaciÃ³n de PyTorch
- [ ] La capa de embedding maneja el procesamiento de parches correctamente
- [ ] La carga de pesos funciona desde archivos CSV

---

## ğŸ“… DÃA 3: Multi-Head Self-Attention (8-10 horas)
**Prioridad: Implementar el mecanismo central del transformer**

### SesiÃ³n Matutina (4-5 horas): Self-Attention BÃ¡sico
Crear `include/transformer/attention.h` y `src/transformer/attention.cpp`:

**Pasos del Mecanismo de AtenciÃ³n:**
1. **Proyecciones Lineales:** Generar matrices Q, K, V
   ```cpp
   Q = input * W_q + b_q
   K = input * W_k + b_k  
   V = input * W_v + b_v
   ```

2. **AtenciÃ³n Escalada Dot-Product:**
   ```cpp
   scores = Q * K^T / sqrt(d_k)
   attention_weights = softmax(scores)
   output = attention_weights * V
   ```

**Detalles CrÃ­ticos de ImplementaciÃ³n:**
- Manejar correctamente la longitud de secuencia y dimensiones de caracterÃ­sticas
- Implementar enmascaramiento de atenciÃ³n (si es necesario)
- Agregar estabilidad numÃ©rica al softmax en atenciÃ³n

### SesiÃ³n Vespertina (4-5 horas): Multi-Head Attention
**Procesamiento Multi-Head:**
1. **Reshape para MÃºltiples Cabezas:**
   - Dividir Q, K, V en `num_heads` piezas
   - Cada cabeza procesa `d_model / num_heads` dimensiones

2. **AtenciÃ³n Paralela:**
   - Aplicar mecanismo de atenciÃ³n a cada cabeza independientemente
   - Mantener pesos de atenciÃ³n separados por cabeza

3. **Concatenar y Proyectar:**
   - Combinar todas las salidas de cabezas
   - Aplicar proyecciÃ³n lineal final

**MÃ©todos Clave:**
- `forward(const Matrix& input)`
- `load_weights(const string& base_path, int layer_idx)` - carga desde tu estructura CSV:
  - `base_path + "/transformer_layers/blocks_X_attn_qkv_weight.csv"`
  - `base_path + "/transformer_layers/blocks_X_attn_qkv_bias.csv"`
  - `base_path + "/transformer_layers/blocks_X_attn_proj_weight.csv"`
  - `base_path + "/transformer_layers/blocks_X_attn_proj_bias.csv"`
- `get_attention_weights()` para visualizaciÃ³n

**Ejemplo de Carga de Pesos:**
```cpp
void MultiHeadAttention::load_weights(const string& base_path, int layer_idx) {
    string prefix = base_path + "/transformer_layers/blocks_" + std::to_string(layer_idx) + "_attn_";
    qkv_weight = load_matrix_from_csv(prefix + "qkv_weight.csv");
    qkv_bias = load_vector_from_csv(prefix + "qkv_bias.csv");
    proj_weight = load_matrix_from_csv(prefix + "proj_weight.csv");
    proj_bias = load_vector_from_csv(prefix + "proj_bias.csv");
}
```

### âš ï¸ DesafÃ­os CrÃ­ticos del DÃ­a 3:
- **Manejo de Dimensiones:** Rastrear formas cuidadosamente (batch_size, seq_len, d_model)
- **Eficiencia de Memoria:** Evitar copias innecesarias durante el reshape
- **Debugging:** Implementar visualizaciÃ³n de pesos de atenciÃ³n

### ğŸ¯ Criterios de Ã‰xito del DÃ­a 3:
- [ ] La atenciÃ³n de una sola cabeza produce formas de salida correctas
- [ ] La atenciÃ³n multi-cabeza combina cabezas apropiadamente
- [ ] Los pesos de atenciÃ³n suman 1.0 a travÃ©s de la dimensiÃ³n de secuencia
- [ ] El rendimiento es aceptable para longitudes de secuencia objetivo

---

## ğŸ“… DÃA 4: MLP y IntegraciÃ³n de Capas Transformer (6-8 horas)
**Prioridad: Completar todos los componentes del transformer**

### SesiÃ³n Matutina (2-3 horas): Red Feed-Forward MLP
Crear `include/transformer/mlp.h` y `src/transformer/mlp.cpp`:

**Arquitectura MLP:**
```cpp
class MLPBlock {
    Matrix fc1_weight, fc1_bias;  // Primera capa lineal
    Matrix fc2_weight, fc2_bias;  // Segunda capa lineal
    
    Matrix forward(const Matrix& input) {
        auto hidden = gelu(input * fc1_weight + fc1_bias);
        return hidden * fc2_weight + fc2_bias;
    }
    
    void load_weights(const string& base_path, int layer_idx) {
        string prefix = base_path + "/transformer_layers/blocks_" + std::to_string(layer_idx) + "_mlp_";
        fc1_weight = load_matrix_from_csv(prefix + "fc1_weight.csv");
        fc1_bias = load_vector_from_csv(prefix + "fc1_bias.csv");
        fc2_weight = load_matrix_from_csv(prefix + "fc2_weight.csv");
        fc2_bias = load_vector_from_csv(prefix + "fc2_bias.csv");
    }
};
```

**Dimensiones TÃ­picas:**
- Entrada: `[seq_len, d_model]`
- Oculta: `[seq_len, 4 * d_model]` (factor de expansiÃ³n de 4)
- Salida: `[seq_len, d_model]`

### SesiÃ³n Vespertina (3-4 horas): Capa Transformer Completa
Crear capa transformer completa en `include/transformer/transformer.h`:

**Estructura del Bloque Transformer:**
```cpp
Matrix transformer_layer(const Matrix& input) {
    // 1. Pre-normalizaciÃ³n + Multi-Head Attention + Residual
    auto norm1_out = layer_norm1.forward(input);
    auto attn_out = multi_head_attention.forward(norm1_out);
    auto residual1 = input + attn_out;  // ConexiÃ³n residual
    
    // 2. Pre-normalizaciÃ³n + MLP + Residual  
    auto norm2_out = layer_norm2.forward(residual1);
    auto mlp_out = mlp.forward(norm2_out);
    return residual1 + mlp_out;  // ConexiÃ³n residual
}
```

### SesiÃ³n Nocturna (2 horas): Stack de MÃºltiples Capas
**Apilamiento de Capas:**
- Implementar bucle sobre N capas transformer
- Mantener pesos separados para cada capa
- Manejar flujo de gradiente a travÃ©s de conexiones residuales

**GestiÃ³n de Pesos:**
- Organizar pesos por capa usando tu estructura CSV:
  - `weights_csv_organized/transformer_layers/blocks_0_*`
  - `weights_csv_organized/transformer_layers/blocks_1_*`
  - etc.
- Implementar carga eficiente de pesos:

```cpp
void TransformerStack::load_all_weights(const string& base_path, int num_layers) {
    for (int i = 0; i < num_layers; i++) {
        layers[i].attention.load_weights(base_path, i);
        layers[i].mlp.load_weights(base_path, i);
        layers[i].norm1.load_weights(base_path, i, "norm1");
        layers[i].norm2.load_weights(base_path, i, "norm2");
    }
}
```

### ğŸ¯ Criterios de Ã‰xito del DÃ­a 4:
- [ ] MLP completamente funcional
- [ ] Una capa transformer completa funcionando
- [ ] Stack de mÃºltiples capas
- [ ] Conexiones residuales correctas

---

## ğŸ“… DÃA 5: IntegraciÃ³n Final y Testing (6-8 horas)
**Prioridad: Modelo completo funcional con validaciÃ³n**

### SesiÃ³n Matutina (3-4 horas): Vision Transformer Completo
Finalizar `include/transformer/transformer.h` y `src/transformer/transformer.cpp`:

**Pipeline Completo de ViT:**
```cpp
class VisionTransformer {
    Matrix forward(const Matrix& image) {
        // 1. Patch embedding + codificaciÃ³n posicional
        auto embedded = patch_embed.forward(image);
        
        // 2. Agregar class token
        auto with_cls = add_class_token(embedded);
        
        // 3. Pasar a travÃ©s de capas transformer
        auto encoded = transformer_stack.forward(with_cls);
        
        // 4. Cabeza de clasificaciÃ³n (usar class token)
        auto cls_token = encoded.get_row(0);  // Primer token
        return classification_head.forward(cls_token);
    }
    
    void load_all_weights(const string& weights_base_path) {
        patch_embed.load_weights(weights_base_path);
        transformer_stack.load_all_weights(weights_base_path, num_layers);
        
        // Cargar clasificador final
        Matrix head_weight = load_matrix_from_csv(weights_base_path + "/classifier/head_weight.csv");
        Matrix head_bias = load_vector_from_csv(weights_base_path + "/classifier/head_bias.csv");
        classification_head.set_weights(head_weight, head_bias);
        
        // Cargar layer norm final
        final_norm.load_weights(weights_base_path + "/layer_norm/", -1, "norm");
    }
};
```

**Procesamiento de ImÃ¡genes:**
- Convertir MNIST 28x28 a parches (ej., parches 4x4 = 49 parches)
- Aplanar parches a vectores
- Agregar embeddings posicionales

### SesiÃ³n Vespertina (2-3 horas): AplicaciÃ³n Principal
Crear `src/main.cpp` y utilidades de soporte:

**CaracterÃ­sticas de la AplicaciÃ³n Principal:**
- Cargar imÃ¡genes de prueba MNIST
- Ejecutar inferencia en imÃ¡genes de muestra
- Mostrar predicciones con puntuaciones de confianza
- Medir tiempo de inferencia

**Utilidades de Procesamiento de ImÃ¡genes:**
- `load_mnist_image(const string& filename)`
- `preprocess_image(const Matrix& image)`
- `postprocess_predictions(const Matrix& logits)`

### SesiÃ³n Nocturna (2 horas): Testing y ValidaciÃ³n
Crear pruebas comprehensivas en `tests/test_complete_model.cpp`:

**Pruebas de ValidaciÃ³n:**
- **Prueba End-to-End:** Ejecutar inferencia en muestras conocidas de MNIST
- **ComparaciÃ³n con PyTorch:** Comparar salidas intermedias con referencia
- **Prueba de Rendimiento:** Medir tiempo de inferencia y uso de memoria
- **Prueba de PrecisiÃ³n:** Validar precisiÃ³n de clasificaciÃ³n en conjunto de prueba

**Herramientas de Debugging:**
- Guardar activaciones intermedias en CSV
- Implementar visualizaciÃ³n de atenciÃ³n
- Agregar profilers de tiempo para cada componente

### ğŸ¯ Criterios de Ã‰xito del DÃ­a 5:
- [ ] El modelo completo ejecuta inferencia exitosamente
- [ ] Las predicciones coinciden con la referencia de PyTorch (dentro de tolerancia)
- [ ] El tiempo de inferencia es razonable (< 1 segundo por imagen)
- [ ] El uso de memoria es estable (sin fugas)

---

## ğŸš€ Mejores PrÃ¡cticas de ImplementaciÃ³n

### Directrices de Calidad de CÃ³digo:
1. **Usar RAII:** GestiÃ³n apropiada de recursos en todas las clases
2. **Correctitud de Const:** Marcar parÃ¡metros de solo lectura como `const`
3. **Manejo de Errores:** Verificar dimensiones y manejar casos extremos
4. **DocumentaciÃ³n:** Comentar operaciones matemÃ¡ticas complejas
5. **Testing:** Escribir pruebas unitarias para cada componente

### Estrategias de Debugging:
1. **VerificaciÃ³n de Forma:** Imprimir dimensiones de matrices en cada paso
2. **InspecciÃ³n de Valores:** Guardar resultados intermedios en archivos
3. **ComparaciÃ³n de Referencia:** Comparar con salidas de PyTorch
4. **Testing Incremental:** Probar cada componente en aislamiento

### Consejos de Rendimiento:
1. **Layout de Memoria:** Usar orden row-major consistentemente
2. **Eficiencia de Cache:** Acceder memoria secuencialmente cuando sea posible
3. **Evitar Copias:** Usar referencias y semÃ¡ntica de movimiento
4. **Perfilar Primero:** Medir antes de optimizar

## âš¡ Planes de Contingencia

### Si Te Atrasas:
- **DÃ­a 1-2:** Usar librerÃ­a Eigen para operaciones de matrices
- **DÃ­a 3:** Implementar solo atenciÃ³n de una cabeza
- **DÃ­a 4:** Probar con menos capas transformer
- **DÃ­a 5:** Enfocarse en funcionalidad bÃ¡sica sobre optimizaciÃ³n

### Si Te Adelantas:
- Agregar paralelizaciÃ³n con OpenMP
- Implementar procesamiento por lotes
- Agregar testing mÃ¡s comprehensivo
- Optimizar uso de memoria y rendimiento

## ğŸ“Š MÃ©tricas de Ã‰xito
- **Funcionalidad:** El modelo produce predicciones razonables de MNIST
- **PrecisiÃ³n:** Dentro del 5% de la implementaciÃ³n de referencia de PyTorch  
- **Rendimiento:** Inferencia bajo 1 segundo por imagen
- **Calidad de CÃ³digo:** Sin fugas de memoria, arquitectura limpia

Â¡Recuerda: EnfÃ³cate en correcciÃ³n primero, optimizaciÃ³n segundo. Una implementaciÃ³n que funciona pero es lenta es infinitamente mejor que una implementaciÃ³n rÃ¡pida que no funciona!